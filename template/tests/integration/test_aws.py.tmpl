import logging
import pytest
import os


@pytest.mark.aws
def test_kms():
    """
    Test AWS KMS Credentials

    Verify AWS credentials can be received from KMS successfully.
    """
    from {{.project_name}}.common import spark_credentials

    client_id, client_secret = spark_credentials.get_credentials_aws()

    assert not client_id is None
    assert not client_secret is None

@pytest.mark.aws
@pytest.mark.spark
@pytest.mark.usefixtures('spark')
def test_aws_spark_credentials(spark):
    """
    Test Spark's AWS Credentials

    Verify AWS credentials can be properly configured in Spark Configuration. This test should be
    ommitted from testing in Databricks as the Spark Configuration won't be accessible.
    """
    from {{.project_name}}.common import spark_credentials

    key_name='spark.hadoop.fs.s3a.access.key'
    secret_name='spark.hadoop.fs.s3a.secret.key'
    client_id, client_secret = spark_credentials.get_credentials_spark_config(spark, key_name, secret_name)

    assert not client_id is None
    assert not client_secret is None